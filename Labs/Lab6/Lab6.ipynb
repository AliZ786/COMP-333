{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mohammad Ali Zahir\n",
    "# ID: 40077619\n",
    "# COMP 333 - Lab 7\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import os\n",
    "import gzip\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset \n",
    "\n",
    "# Creating the data folder\n",
    "if not os.path.exists('./data'):\n",
    "\tos.makedirs('./data')\n",
    "\n",
    "# Obtaining the dataset using the url that hosts it\n",
    "kaggle_url = 'https://github.com/sundeepblue/movie_rating_prediction/raw/master/movie_metadata.csv'\n",
    "if not os.path.exists('./data/kaggle_dataset.csv'):     # avoid downloading if the file exists\n",
    "\tresponse = urllib.urlretrieve(kaggle_url, './data/kaggle_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Obtaining IMDB's text files\n",
    "imdb_url_prefix = 'ftp://ftp.funet.fi/pub/mirrors/ftp.imdb.com/pub/'\n",
    "imdb_files_list = ['genres.list.gz', 'ratings.list.gz']\n",
    "for name in imdb_files_list:\n",
    "\tif not os.path.exists('./data/' + name):\n",
    "\t\tresponse = urllib.request.urlretrieve(imdb_url_prefix + name, './data/' + name)\n",
    "\t\turllib.urlcleanup()   # urllib fails to download two files from a ftp source. This fixes the bug!\n",
    "\t\twith gzip.open('./data/' + name) as comp_file, open('./data/' + name[:-3], 'w') as reg_file:\n",
    "\t\t\tfile_content = comp_file.read()\n",
    "\t\t\treg_file.write(file_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the dataset file\n",
    "\n",
    "imdb_url = 'https://anaconda.org/BigGorilla/datasets/1/download/imdb_dataset.csv'\n",
    "if not os.path.exists('./data/imdb_dataset.csv'):     # avoid downloading if the file exists\n",
    "\tresponse = urllib.urlretrieve(kaggle_url, './data/imdb_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0000000125  1888533   9.2  The Shawshank Redemption (1994)\n",
      "      0000000125  1289428   9.2  The Godfather (1972)\n",
      "      0000000124  889607   9.0  The Godfather: Part II (1974)\n",
      "      0000000124  1864164   9.0  The Dark Knight (2008)\n",
      "      0000000133  518449   8.9  12 Angry Men (1957)\n",
      "      0000000133  971107   8.9  Schindler's List (1993)\n",
      "      0000000123  1477112   8.9  Pulp Fiction (1994)\n",
      "      0000000124  1349449   8.9  The Lord of the Rings: The Return of the King (2003)\n",
      "      0000000123  559468   8.8  Il buono, il brutto, il cattivo (1966)\n",
      "      0000000133  1513600   8.8  Fight Club (1999)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Open the ratings file\n",
    "\n",
    "with open(\"./data/ratings.list\", encoding=\"ISO-8859-1\") as myfile:\n",
    "\thead = [next(myfile) for x in range(38)]\n",
    "print (''.join(head[28:38]))   # skipping the first 28 lines as they are descriptive headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "\n",
      "\"!Next?\" (1994)\t\t\t\t\t\tDocumentary\n",
      "\"#1 Single\" (2006)\t\t\t\t\tReality-TV\n",
      "\"#15SecondScare\" (2015)\t\t\t\t\tHorror\n",
      "\"#15SecondScare\" (2015)\t\t\t\t\tShort\n",
      "\"#15SecondScare\" (2015)\t\t\t\t\tThriller\n",
      "\"#15SecondScare\" (2015) {Who Wants to Play with the Rabbit? (#1.2)}\tDrama\n",
      "\"#15SecondScare\" (2015) {Who Wants to Play with the Rabbit? (#1.2)}\tHorror\n",
      "\"#15SecondScare\" (2015) {Who Wants to Play with the Rabbit? (#1.2)}\tShort\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Opening the genre file\n",
    "with open(\"./data/genres.list\", encoding=\"ISO-8859-1\") as myfile:\n",
    "\thead = [next(myfile) for x in range(392)]\n",
    "print (''.join(head[382:392]))   # skipping the first 382 lines as they are descriptive header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the information in genres.list \n",
    "with open(\"./data/genres.list\", encoding=\"ISO-8859-1\") as genres_file:\n",
    "\traw_content = genres_file.readlines()\n",
    "\tgenres_list = []\n",
    "\tcontent = raw_content[400:]\n",
    "\tfor line in content:\n",
    "\t\tm = re.match(r'\"?(.*[^\"])\"? \\(((?:\\d|\\?){4})(?:/\\w*)?\\).*\\s((?:\\w|-)+)', line.strip())\n",
    "\t\tgenres_list.append([m.group(1), m.group(2), m.group(3)])\n",
    "\tgenres_data = pd.DataFrame(genres_list, columns=['movie', 'year', 'genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the info from ratings.list \n",
    "\n",
    "with open(\"./data/ratings.list\", encoding=\"ISO-8859-1\") as ratings_file:\n",
    "\traw_content = ratings_file.readlines()\n",
    "\tratings_list = []\n",
    "\tcontent = raw_content[28:]\n",
    "\tfor line in content:\n",
    "\t\tm = re.match(r'(?:\\d|\\.|\\*){10}\\s+\\d+\\s+(1?\\d\\.\\d)\\s\"?(.*[^\"])\"? \\(((?:\\d|\\?){4})(?:/\\w*)?\\)', line.strip())\n",
    "\t\tif m is None: continue\n",
    "\t\tratings_list.append([m.group(2), m.group(3), m.group(1)])\n",
    "\tratings_data = pd.DataFrame(ratings_list, columns=['movie', 'year', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Kaggle dataset from the .csv file (kaggle_dataset.csv)\n",
    "kaggle_data = pd.read_csv('./data/kaggle_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies in kaggle_data: 5043\n",
      "Number of movies in genres_data: 2658925\n",
      "Number of movies in ratings_data: 789415\n"
     ]
    }
   ],
   "source": [
    "# Calculating some basic statistics about the dataset\n",
    "print ('Number of movies in kaggle_data: {}'.format(kaggle_data.shape[0]))\n",
    "print ('Number of movies in genres_data: {}'.format(genres_data.shape[0]))\n",
    "print ('Number of movies in ratings_data: {}'.format(ratings_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates in kaggle_data: 241\n",
      "Number of duplicates in genres_data: 2031315\n",
      "Number of duplicates in ratings_data: 342815\n"
     ]
    }
   ],
   "source": [
    "# Print number of duplicates\n",
    "print ('Number of duplicates in kaggle_data: {}'.format(\n",
    "\tsum(kaggle_data.duplicated(subset=['movie_title', 'title_year'], keep=False))))\n",
    "print ('Number of duplicates in genres_data: {}'.format(\n",
    "\tsum(genres_data.duplicated(subset=['movie', 'year'], keep=False))))\n",
    "print ('Number of duplicates in ratings_data: {}'.format(\n",
    "\tsum(ratings_data.duplicated(subset=['movie', 'year'], keep=False))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the duplicates\n",
    "kaggle_data = kaggle_data.drop_duplicates(subset=['movie_title', 'title_year'], keep='first').copy()\n",
    "genres_data = genres_data.drop_duplicates(subset=['movie', 'year'], keep='first').copy()\n",
    "ratings_data = ratings_data.drop_duplicates(subset=['movie', 'year'], keep='first').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning - normalizing the text \n",
    "\n",
    "def preprocess_title(title):\n",
    "\ttitle = title.lower()\n",
    "\ttitle = title.replace(',', ' ')\n",
    "\ttitle = title.replace(\"'\", '')    \n",
    "\ttitle = title.replace('&', 'and')\n",
    "\ttitle = title.replace('?', '')\n",
    "\treturn title.strip()\n",
    "\n",
    "kaggle_data['norm_movie_title'] = kaggle_data['movie_title'].map(preprocess_title)\n",
    "genres_data['norm_movie'] = genres_data['movie'].map(preprocess_title)\n",
    "ratings_data['norm_movie'] = ratings_data['movie'].map(preprocess_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>director_name</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_2_name</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>genres</th>\n",
       "      <th>...</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "      <th>norm_movie_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4422</th>\n",
       "      <td>Color</td>\n",
       "      <td>Simeon Rice</td>\n",
       "      <td>6.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Lisa Brave</td>\n",
       "      <td>393.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Action|Horror|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>R</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.35</td>\n",
       "      <td>307</td>\n",
       "      <td>unsullied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>Color</td>\n",
       "      <td>Doug Liman</td>\n",
       "      <td>214.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>Ty Burrell</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>9528092.0</td>\n",
       "      <td>Biography|Drama|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>22000000.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.35</td>\n",
       "      <td>9000</td>\n",
       "      <td>fair game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>Color</td>\n",
       "      <td>Jonathan Levine</td>\n",
       "      <td>147.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>Aaron Yoo</td>\n",
       "      <td>976.0</td>\n",
       "      <td>2077046.0</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>R</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>617.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "      <td>the wackness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      color    director_name  num_critic_for_reviews  duration  \\\n",
       "4422  Color      Simeon Rice                     6.0      93.0   \n",
       "1022  Color       Doug Liman                   214.0     108.0   \n",
       "3631  Color  Jonathan Levine                   147.0      99.0   \n",
       "\n",
       "      director_facebook_likes  actor_3_facebook_likes actor_2_name  \\\n",
       "4422                      6.0                    56.0   Lisa Brave   \n",
       "1022                    218.0                   405.0   Ty Burrell   \n",
       "3631                    129.0                   362.0    Aaron Yoo   \n",
       "\n",
       "      actor_1_facebook_likes      gross                    genres  ...  \\\n",
       "4422                   393.0        NaN    Action|Horror|Thriller  ...   \n",
       "1022                  6000.0  9528092.0  Biography|Drama|Thriller  ...   \n",
       "3631                   976.0  2077046.0      Comedy|Drama|Romance  ...   \n",
       "\n",
       "     language country  content_rating      budget title_year  \\\n",
       "4422  English     USA               R   1500000.0     2014.0   \n",
       "1022  English     USA           PG-13  22000000.0     2010.0   \n",
       "3631  English     USA               R   6000000.0     2008.0   \n",
       "\n",
       "      actor_2_facebook_likes imdb_score aspect_ratio  movie_facebook_likes  \\\n",
       "4422                   191.0        5.5         2.35                   307   \n",
       "1022                  3000.0        6.8         2.35                  9000   \n",
       "3631                   617.0        7.0         2.35                     0   \n",
       "\n",
       "     norm_movie_title  \n",
       "4422        unsullied  \n",
       "1022        fair game  \n",
       "3631     the wackness  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at samples of data\n",
    "\n",
    "kaggle_data.sample(3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>director_name</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_2_name</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>genres</th>\n",
       "      <th>...</th>\n",
       "      <th>country</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "      <th>norm_movie_title</th>\n",
       "      <th>norm_title_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Color</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>723.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>Joel David Moore</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>760505847.0</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>237000000.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.78</td>\n",
       "      <td>33000</td>\n",
       "      <td>avatar</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Color</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>302.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Orlando Bloom</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>309404152.0</td>\n",
       "      <td>Action|Adventure|Fantasy</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "      <td>pirates of the caribbean: at worlds end</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Color</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>602.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>Rory Kinnear</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>200074175.0</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>UK</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>245000000.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.35</td>\n",
       "      <td>85000</td>\n",
       "      <td>spectre</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Color</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>813.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>Christian Bale</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>448130642.0</td>\n",
       "      <td>Action|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2.35</td>\n",
       "      <td>164000</td>\n",
       "      <td>the dark knight rises</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Doug Walker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rob Walker</td>\n",
       "      <td>131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>star wars: episode vii - the force awakens</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   color      director_name  num_critic_for_reviews  duration  \\\n",
       "0  Color      James Cameron                   723.0     178.0   \n",
       "1  Color     Gore Verbinski                   302.0     169.0   \n",
       "2  Color         Sam Mendes                   602.0     148.0   \n",
       "3  Color  Christopher Nolan                   813.0     164.0   \n",
       "4    NaN        Doug Walker                     NaN       NaN   \n",
       "\n",
       "   director_facebook_likes  actor_3_facebook_likes      actor_2_name  \\\n",
       "0                      0.0                   855.0  Joel David Moore   \n",
       "1                    563.0                  1000.0     Orlando Bloom   \n",
       "2                      0.0                   161.0      Rory Kinnear   \n",
       "3                  22000.0                 23000.0    Christian Bale   \n",
       "4                    131.0                     NaN        Rob Walker   \n",
       "\n",
       "   actor_1_facebook_likes        gross                           genres  ...  \\\n",
       "0                  1000.0  760505847.0  Action|Adventure|Fantasy|Sci-Fi  ...   \n",
       "1                 40000.0  309404152.0         Action|Adventure|Fantasy  ...   \n",
       "2                 11000.0  200074175.0        Action|Adventure|Thriller  ...   \n",
       "3                 27000.0  448130642.0                  Action|Thriller  ...   \n",
       "4                   131.0          NaN                      Documentary  ...   \n",
       "\n",
       "  country content_rating       budget  title_year actor_2_facebook_likes  \\\n",
       "0     USA          PG-13  237000000.0      2009.0                  936.0   \n",
       "1     USA          PG-13  300000000.0      2007.0                 5000.0   \n",
       "2      UK          PG-13  245000000.0      2015.0                  393.0   \n",
       "3     USA          PG-13  250000000.0      2012.0                23000.0   \n",
       "4     NaN            NaN          NaN         NaN                   12.0   \n",
       "\n",
       "   imdb_score aspect_ratio movie_facebook_likes  \\\n",
       "0         7.9         1.78                33000   \n",
       "1         7.1         2.35                    0   \n",
       "2         6.8         2.35                85000   \n",
       "3         8.5         2.35               164000   \n",
       "4         7.1          NaN                    0   \n",
       "\n",
       "                             norm_movie_title norm_title_year  \n",
       "0                                      avatar            2009  \n",
       "1     pirates of the caribbean: at worlds end            2007  \n",
       "2                                     spectre            2015  \n",
       "3                       the dark knight rises            2012  \n",
       "4  star wars: episode vii - the force awakens               ?  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing null values from the dataset \n",
    "\n",
    "def preprocess_year(year):\n",
    "\tif pd.isnull(year):\n",
    "\t\treturn '?'\n",
    "\telse:\n",
    "\t\treturn str(int(year))\n",
    "\n",
    "kaggle_data['norm_title_year'] = kaggle_data['title_year'].map(preprocess_year)\n",
    "kaggle_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_x</th>\n",
       "      <th>year</th>\n",
       "      <th>rating</th>\n",
       "      <th>norm_movie</th>\n",
       "      <th>movie_y</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>9.2</td>\n",
       "      <td>the shawshank redemption</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.2</td>\n",
       "      <td>the godfather</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>1974</td>\n",
       "      <td>9.0</td>\n",
       "      <td>the godfather: part ii</td>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.0</td>\n",
       "      <td>the dark knight</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>1957</td>\n",
       "      <td>8.9</td>\n",
       "      <td>12 angry men</td>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>Crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     movie_x  year rating                norm_movie  \\\n",
       "0   The Shawshank Redemption  1994    9.2  the shawshank redemption   \n",
       "1              The Godfather  1972    9.2             the godfather   \n",
       "2     The Godfather: Part II  1974    9.0    the godfather: part ii   \n",
       "3            The Dark Knight  2008    9.0           the dark knight   \n",
       "4               12 Angry Men  1957    8.9              12 angry men   \n",
       "\n",
       "                    movie_y   genre  \n",
       "0  The Shawshank Redemption   Crime  \n",
       "1             The Godfather   Crime  \n",
       "2    The Godfather: Part II   Crime  \n",
       "3           The Dark Knight  Action  \n",
       "4              12 Angry Men   Crime  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LAB 7 starts here\n",
    "\n",
    "# Added brief data \n",
    "brief_imdb_data = pd.merge(ratings_data, genres_data, how='inner', on=['norm_movie', 'year'])\n",
    "brief_imdb_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(869178, 27)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the new IMDB dataset\n",
    "imdb_data = pd.read_csv('./data/imdb_dataset.csv')\n",
    "# let's normlize the title as we did in Part 3 of the tutorial\n",
    "imdb_data['norm_title'] = imdb_data['title'].map(preprocess_title)\n",
    "imdb_data['norm_year'] = imdb_data['year'].map(preprocess_year)\n",
    "imdb_data = imdb_data.drop_duplicates(subset=['norm_title', 'norm_year'], keep='first').copy()\n",
    "imdb_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4248, 57)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merged data table \n",
    "\n",
    "data_attempt1 = pd.merge(imdb_data, kaggle_data, how='inner', left_on=['norm_title', 'norm_year'],\n",
    "\t\t\t\t\t\t right_on=['norm_movie_title', 'norm_title_year'])\n",
    "data_attempt1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py-stringsimjoin\n",
      "  Downloading py_stringsimjoin-0.3.2.tar.gz (1.1 MB)\n",
      "Requirement already satisfied: joblib in c:\\users\\ali\\appdata\\roaming\\python\\python39\\site-packages (from py-stringsimjoin) (1.0.1)\n",
      "Requirement already satisfied: pandas>=0.16.0 in c:\\users\\ali\\miniconda3\\lib\\site-packages (from py-stringsimjoin) (1.5.3)\n",
      "Collecting PyPrind>=2.9.3\n",
      "  Downloading PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n",
      "Collecting py_stringmatching>=0.2.1\n",
      "  Downloading py_stringmatching-0.4.2.tar.gz (661 kB)\n",
      "Requirement already satisfied: six in c:\\users\\ali\\appdata\\roaming\\python\\python39\\site-packages (from py-stringsimjoin) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ali\\miniconda3\\lib\\site-packages (from pandas>=0.16.0->py-stringsimjoin) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\ali\\miniconda3\\lib\\site-packages (from pandas>=0.16.0->py-stringsimjoin) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ali\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=0.16.0->py-stringsimjoin) (2.8.2)\n",
      "Building wheels for collected packages: py-stringsimjoin, py-stringmatching\n",
      "  Building wheel for py-stringsimjoin (setup.py): started\n",
      "  Building wheel for py-stringsimjoin (setup.py): finished with status 'done'\n",
      "  Created wheel for py-stringsimjoin: filename=py_stringsimjoin-0.3.2-cp39-cp39-win_amd64.whl size=1619697 sha256=2728a97a3caff7a64fa600a960f8d60a6fb22dde9df25c6e0f072146c1373522\n",
      "  Stored in directory: c:\\users\\ali\\appdata\\local\\pip\\cache\\wheels\\e4\\77\\dd\\ffb13103ce962a7fffed97cc67493274cd1d6aeb0eff251905\n",
      "  Building wheel for py-stringmatching (setup.py): started\n",
      "  Building wheel for py-stringmatching (setup.py): finished with status 'done'\n",
      "  Created wheel for py-stringmatching: filename=py_stringmatching-0.4.2-cp39-cp39-win_amd64.whl size=1016889 sha256=a2a3ff94aac2fe5dbae0e31f3ed8aafd95a12b0b78072ca4bce78b64f08eef35\n",
      "  Stored in directory: c:\\users\\ali\\appdata\\local\\pip\\cache\\wheels\\58\\0c\\f7\\e3a0eb45dabc837a8c24b1f46a1210b1d9050f198d0bb59910\n",
      "Successfully built py-stringsimjoin py-stringmatching\n",
      "Installing collected packages: PyPrind, py-stringmatching, py-stringsimjoin\n",
      "Successfully installed PyPrind-2.11.3 py-stringmatching-0.4.2 py-stringsimjoin-0.3.2\n",
      "Requirement already satisfied: py_stringmatching in c:\\users\\ali\\miniconda3\\lib\\site-packages (0.4.2)\n",
      "Requirement already satisfied: six in c:\\users\\ali\\appdata\\roaming\\python\\python39\\site-packages (from py_stringmatching) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.7.0 in c:\\users\\ali\\miniconda3\\lib\\site-packages (from py_stringmatching) (1.20.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ali\\miniconda3\\lib\\site-packages\\py_stringsimjoin\\utils\\generic_helper.py:76: FutureWarning: In a future version of pandas all arguments of DataFrame.dropna will be keyword-only.\n",
      "  projected_dataframe = dataframe[proj_attrs].dropna(0,\n",
      "c:\\Users\\Ali\\miniconda3\\lib\\site-packages\\py_stringsimjoin\\utils\\generic_helper.py:76: FutureWarning: In a future version of pandas all arguments of DataFrame.dropna will be keyword-only.\n",
      "  projected_dataframe = dataframe[proj_attrs].dropna(0,\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4679, 8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Added new imports\n",
    "# !pip install py-stringsimjoin\n",
    "# !pip install py_stringmatching\n",
    "\n",
    "import py_stringsimjoin as ssj\n",
    "import py_stringmatching as sm\n",
    "\n",
    "imdb_data['id'] = range(imdb_data.shape[0])\n",
    "kaggle_data['id'] = range(kaggle_data.shape[0])\n",
    "similar_titles = ssj.edit_distance_join(imdb_data, kaggle_data, 'id', 'id', 'norm_title',\n",
    "\t\t\t\t\t\t\t\t\t\t'norm_movie_title', l_out_attrs=['norm_title', 'norm_year'],\n",
    "\t\t\t\t\t\t\t\t\t\t r_out_attrs=['norm_movie_title', 'norm_title_year'], threshold=1)\n",
    "# selecting the entries that have the same production year\n",
    "data_attempt2 = similar_titles[similar_titles.r_norm_title_year == similar_titles.l_norm_year]\n",
    "data_attempt2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>l_id</th>\n",
       "      <th>r_id</th>\n",
       "      <th>l_norm_title</th>\n",
       "      <th>l_norm_year</th>\n",
       "      <th>r_norm_movie_title</th>\n",
       "      <th>r_norm_title_year</th>\n",
       "      <th>_sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>145</td>\n",
       "      <td>852736</td>\n",
       "      <td>46</td>\n",
       "      <td>world war v</td>\n",
       "      <td>2013</td>\n",
       "      <td>world war z</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>281649</td>\n",
       "      <td>56</td>\n",
       "      <td>grave</td>\n",
       "      <td>2012</td>\n",
       "      <td>brave</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>243</td>\n",
       "      <td>816188</td>\n",
       "      <td>67</td>\n",
       "      <td>upe</td>\n",
       "      <td>2009</td>\n",
       "      <td>up</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>250</td>\n",
       "      <td>817366</td>\n",
       "      <td>67</td>\n",
       "      <td>ut</td>\n",
       "      <td>2009</td>\n",
       "      <td>up</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>265</td>\n",
       "      <td>316745</td>\n",
       "      <td>70</td>\n",
       "      <td>hug</td>\n",
       "      <td>2011</td>\n",
       "      <td>hugo</td>\n",
       "      <td>2011</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _id    l_id  r_id l_norm_title l_norm_year r_norm_movie_title  \\\n",
       "145  145  852736    46  world war v        2013        world war z   \n",
       "175  175  281649    56        grave        2012              brave   \n",
       "243  243  816188    67          upe        2009                 up   \n",
       "250  250  817366    67           ut        2009                 up   \n",
       "265  265  316745    70          hug        2011               hugo   \n",
       "\n",
       "    r_norm_title_year  _sim_score  \n",
       "145              2013         1.0  \n",
       "175              2012         1.0  \n",
       "243              2009         1.0  \n",
       "250              2009         1.0  \n",
       "265              2011         1.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print some values from the top of the table\n",
    "data_attempt2[data_attempt2.l_norm_title != data_attempt2.r_norm_movie_title].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the \"budget\" column into string and creating a new **mixture** column\n",
    "ssj.utils.converter.dataframe_column_to_str(imdb_data, 'budget', inplace=True)\n",
    "imdb_data['mixture'] = imdb_data['norm_title'] + ' ' + imdb_data['norm_year'] + ' ' + imdb_data['budget']\n",
    "\n",
    "# repeating the same thing for the Kaggle dataset\n",
    "ssj.utils.converter.dataframe_column_to_str(kaggle_data, 'budget', inplace=True)\n",
    "kaggle_data['mixture'] = kaggle_data['norm_movie_title'] + ' ' + kaggle_data['norm_title_year'] +  ' ' + kaggle_data['budget']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ali\\miniconda3\\lib\\site-packages\\py_stringsimjoin\\utils\\generic_helper.py:76: FutureWarning: In a future version of pandas all arguments of DataFrame.dropna will be keyword-only.\n",
      "  projected_dataframe = dataframe[proj_attrs].dropna(0,\n",
      "c:\\Users\\Ali\\miniconda3\\lib\\site-packages\\py_stringsimjoin\\utils\\generic_helper.py:76: FutureWarning: In a future version of pandas all arguments of DataFrame.dropna will be keyword-only.\n",
      "  projected_dataframe = dataframe[proj_attrs].dropna(0,\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18317, 14)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating candidate set C\n",
    "C = ssj.overlap_coefficient_join(kaggle_data, imdb_data, 'id', 'id', 'mixture', 'mixture', sm.WhitespaceTokenizer(), \n",
    "\t\t\t\t\t\t\t\t l_out_attrs=['norm_movie_title', 'norm_title_year', 'duration',\n",
    "\t\t\t\t\t\t\t\t\t\t\t  'budget', 'content_rating'],\n",
    "\t\t\t\t\t\t\t\t r_out_attrs=['norm_title', 'norm_year', 'length', 'budget', 'mpaa'],\n",
    "\t\t\t\t\t\t\t\t threshold=0.65)\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py_entitymatching\n",
      "  Downloading py_entitymatching-0.4.0.tar.gz (2.0 MB)\n",
      "Requirement already satisfied: requests in c:\\users\\ali\\miniconda3\\lib\\site-packages (from py_entitymatching) (2.27.1)\n",
      "Requirement already satisfied: ipython>=5.6 in c:\\users\\ali\\miniconda3\\lib\\site-packages (from py_entitymatching) (8.3.0)\n",
      "Requirement already satisfied: matplotlib>=2.2.4 in c:\\users\\ali\\appdata\\roaming\\python\\python39\\site-packages (from py_entitymatching) (3.4.3)\n",
      "Requirement already satisfied: PyPrind in c:\\users\\ali\\miniconda3\\lib\\site-packages (from py_entitymatching) (2.11.3)\n",
      "Requirement already satisfied: py-stringsimjoin>=0.3.0 in c:\\users\\ali\\miniconda3\\lib\\site-packages (from py_entitymatching) (0.3.2)\n",
      "Collecting cloudpickle>=0.2.1\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\ali\\appdata\\roaming\\python\\python39\\site-packages (from py_entitymatching) (2.4.7)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\ali\\appdata\\roaming\\python\\python39\\site-packages (from py_entitymatching) (1.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\ali\\appdata\\roaming\\python\\python39\\site-packages (from py_entitymatching) (1.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ali\\miniconda3\\lib\\site-packages (from py_entitymatching) (1.20.3)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\ali\\miniconda3\\lib\\site-packages (from ipython>=5.6->py_entitymatching) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\ali\\miniconda3\\lib\\site-packages (from ipython>=5.6->py_entitymatching) (61.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ali\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=5.6->py_entitymatching) (0.4.4)\n",
      "Requirement already satisfied: decorator in c:\\users\\ali\\miniconda3\\lib\\site-packages (from ipython>=5.6->py_entitymatching) (5.1.1)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\ali\\miniconda3\\lib\\site-packages (from ipython>=5.6->py_entitymatching) (5.1.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\ali\\miniconda3\\lib\\site-packages (from ipython>=5.6->py_entitymatching) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\ali\\miniconda3\\lib\\site-packages (from ipython>=5.6->py_entitymatching) (0.18.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\ali\\miniconda3\\lib\\site-packages (from ipython>=5.6->py_entitymatching) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\ali\\miniconda3\\lib\\site-packages (from ipython>=5.6->py_entitymatching) (3.0.20)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\ali\\miniconda3\\lib\\site-packages (from ipython>=5.6->py_entitymatching) (0.1.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\ali\\miniconda3\\lib\\site-packages (from ipython>=5.6->py_entitymatching) (2.11.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\ali\\miniconda3\\lib\\site-packages (from jedi>=0.16->ipython>=5.6->py_entitymatching) (0.8.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ali\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=2.2.4->py_entitymatching) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ali\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=2.2.4->py_entitymatching) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ali\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=2.2.4->py_entitymatching) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ali\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib>=2.2.4->py_entitymatching) (8.3.2)\n",
      "Requirement already satisfied: six in c:\\users\\ali\\appdata\\roaming\\python\\python39\\site-packages (from cycler>=0.10->matplotlib>=2.2.4->py_entitymatching) (1.16.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ali\\miniconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.6->py_entitymatching) (0.2.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\ali\\appdata\\roaming\\python\\python39\\site-packages (from py-stringsimjoin>=0.3.0->py_entitymatching) (1.0.1)\n",
      "Requirement already satisfied: py-stringmatching>=0.2.1 in c:\\users\\ali\\miniconda3\\lib\\site-packages (from py-stringsimjoin>=0.3.0->py_entitymatching) (0.4.2)\n",
      "Requirement already satisfied: pandas>=0.16.0 in c:\\users\\ali\\miniconda3\\lib\\site-packages (from py-stringsimjoin>=0.3.0->py_entitymatching) (1.5.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ali\\miniconda3\\lib\\site-packages (from pandas>=0.16.0->py-stringsimjoin>=0.3.0->py_entitymatching) (2022.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ali\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn>=0.22->py_entitymatching) (3.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ali\\miniconda3\\lib\\site-packages (from requests->py_entitymatching) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ali\\miniconda3\\lib\\site-packages (from requests->py_entitymatching) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ali\\miniconda3\\lib\\site-packages (from requests->py_entitymatching) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ali\\miniconda3\\lib\\site-packages (from requests->py_entitymatching) (3.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\ali\\miniconda3\\lib\\site-packages (from stack-data->ipython>=5.6->py_entitymatching) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\ali\\miniconda3\\lib\\site-packages (from stack-data->ipython>=5.6->py_entitymatching) (0.2.2)\n",
      "Requirement already satisfied: executing in c:\\users\\ali\\miniconda3\\lib\\site-packages (from stack-data->ipython>=5.6->py_entitymatching) (0.8.3)\n",
      "Building wheels for collected packages: py-entitymatching\n",
      "  Building wheel for py-entitymatching (setup.py): started\n",
      "  Building wheel for py-entitymatching (setup.py): finished with status 'done'\n",
      "  Created wheel for py-entitymatching: filename=py_entitymatching-0.4.0-cp39-cp39-win_amd64.whl size=2212776 sha256=d43a8689d13292f1e251a543502c671f2926b04dff40b2ce6c8bcf7c78fe3dc3\n",
      "  Stored in directory: c:\\users\\ali\\appdata\\local\\pip\\cache\\wheels\\dd\\87\\08\\44967081e457c8c0915c6b18caa629362b2efbd05f946f9fba\n",
      "Successfully built py-entitymatching\n",
      "Installing collected packages: cloudpickle, py-entitymatching\n",
      "Successfully installed cloudpickle-2.2.1 py-entitymatching-0.4.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specifying the keys\n",
    "\n",
    "# !pip install py_entitymatching\n",
    "import py_entitymatching as em\n",
    "em.set_key(kaggle_data, 'id')   # specifying the key column in the kaggle dataset\n",
    "em.set_key(imdb_data, 'id')     # specifying the key column in the imdb dataset\n",
    "em.set_key(C, '_id')            # specifying the key in the candidate set\n",
    "em.set_ltable(C, kaggle_data)   # specifying the left table \n",
    "em.set_rtable(C, imdb_data)     # specifying the right table\n",
    "em.set_fk_rtable(C, 'r_id')     # specifying the column that matches the key in the right table \n",
    "em.set_fk_ltable(C, 'l_id')     # specifying the column that matches the key in the left table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l_norm_movie_title</th>\n",
       "      <th>r_norm_title</th>\n",
       "      <th>l_norm_title_year</th>\n",
       "      <th>r_norm_year</th>\n",
       "      <th>l_budget</th>\n",
       "      <th>r_budget</th>\n",
       "      <th>l_content_rating</th>\n",
       "      <th>r_mpaa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dude  wheres my dog!</td>\n",
       "      <td>#hacked</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "      <td>PG</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>road hard</td>\n",
       "      <td>#horror</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>1500000</td>\n",
       "      <td>1500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>me you and five bucks</td>\n",
       "      <td>#horror</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>1500000</td>\n",
       "      <td>1500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>checkmate</td>\n",
       "      <td>#horror</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>1500000</td>\n",
       "      <td>1500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#horror</td>\n",
       "      <td>#horror</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015</td>\n",
       "      <td>1500000</td>\n",
       "      <td>1500000</td>\n",
       "      <td>Not Rated</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      l_norm_movie_title r_norm_title l_norm_title_year r_norm_year l_budget  \\\n",
       "0   dude  wheres my dog!      #hacked              2014        2014    20000   \n",
       "1              road hard      #horror              2015        2015  1500000   \n",
       "2  me you and five bucks      #horror              2015        2015  1500000   \n",
       "3              checkmate      #horror              2015        2015  1500000   \n",
       "4                #horror      #horror              2015        2015  1500000   \n",
       "\n",
       "  r_budget l_content_rating r_mpaa  \n",
       "0    20000               PG    NaN  \n",
       "1  1500000              NaN    NaN  \n",
       "2  1500000              NaN    NaN  \n",
       "3  1500000              NaN    NaN  \n",
       "4  1500000        Not Rated    NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debugging the blocker\n",
    "C[['l_norm_movie_title', 'r_norm_title', 'l_norm_title_year', 'r_norm_year',\n",
    "   'l_budget', 'r_budget', 'l_content_rating', 'r_mpaa']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling 500 pairs and writing this sample into a .csv file\n",
    "sampled = C.sample(500, random_state=0)\n",
    "sampled.to_csv('./data/sampled.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>_id</th>\n",
       "      <th>l_id</th>\n",
       "      <th>r_id</th>\n",
       "      <th>l_norm_movie_title</th>\n",
       "      <th>l_norm_title_year</th>\n",
       "      <th>l_duration</th>\n",
       "      <th>l_budget</th>\n",
       "      <th>l_content_rating</th>\n",
       "      <th>r_norm_title</th>\n",
       "      <th>r_norm_year</th>\n",
       "      <th>r_length</th>\n",
       "      <th>r_budget</th>\n",
       "      <th>r_mpaa</th>\n",
       "      <th>_sim_score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4771</td>\n",
       "      <td>4771</td>\n",
       "      <td>2639</td>\n",
       "      <td>235925</td>\n",
       "      <td>eye of the beholder</td>\n",
       "      <td>1999</td>\n",
       "      <td>109.0</td>\n",
       "      <td>15000000</td>\n",
       "      <td>R</td>\n",
       "      <td>eye of the beholder</td>\n",
       "      <td>1999</td>\n",
       "      <td>109.0</td>\n",
       "      <td>35000000</td>\n",
       "      <td>R</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11478</td>\n",
       "      <td>11478</td>\n",
       "      <td>2001</td>\n",
       "      <td>600301</td>\n",
       "      <td>rocky balboa</td>\n",
       "      <td>2006</td>\n",
       "      <td>139.0</td>\n",
       "      <td>24000000</td>\n",
       "      <td>PG</td>\n",
       "      <td>rocky balboa</td>\n",
       "      <td>2006</td>\n",
       "      <td>139.0</td>\n",
       "      <td>24000000</td>\n",
       "      <td>PG</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13630</td>\n",
       "      <td>13630</td>\n",
       "      <td>4160</td>\n",
       "      <td>691766</td>\n",
       "      <td>from russia with love</td>\n",
       "      <td>1963</td>\n",
       "      <td>115.0</td>\n",
       "      <td>2000000</td>\n",
       "      <td>Approved</td>\n",
       "      <td>the aeolians: from russia with love</td>\n",
       "      <td>2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1972</td>\n",
       "      <td>1972</td>\n",
       "      <td>1248</td>\n",
       "      <td>101029</td>\n",
       "      <td>sex tape</td>\n",
       "      <td>2014</td>\n",
       "      <td>94.0</td>\n",
       "      <td>40000000</td>\n",
       "      <td>R</td>\n",
       "      <td>blended</td>\n",
       "      <td>2014</td>\n",
       "      <td>117.0</td>\n",
       "      <td>40000000</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15903</td>\n",
       "      <td>15903</td>\n",
       "      <td>722</td>\n",
       "      <td>758133</td>\n",
       "      <td>the scorch trials</td>\n",
       "      <td>2015</td>\n",
       "      <td>132.0</td>\n",
       "      <td>61000000</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>the scorch trials</td>\n",
       "      <td>2015</td>\n",
       "      <td>132.0</td>\n",
       "      <td>61000000</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    _id  l_id    r_id     l_norm_movie_title  l_norm_title_year  \\\n",
       "0        4771   4771  2639  235925    eye of the beholder               1999   \n",
       "1       11478  11478  2001  600301           rocky balboa               2006   \n",
       "2       13630  13630  4160  691766  from russia with love               1963   \n",
       "3        1972   1972  1248  101029               sex tape               2014   \n",
       "4       15903  15903   722  758133      the scorch trials               2015   \n",
       "\n",
       "   l_duration  l_budget l_content_rating                         r_norm_title  \\\n",
       "0       109.0  15000000                R                  eye of the beholder   \n",
       "1       139.0  24000000               PG                         rocky balboa   \n",
       "2       115.0   2000000         Approved  the aeolians: from russia with love   \n",
       "3        94.0  40000000                R                              blended   \n",
       "4       132.0  61000000            PG-13                    the scorch trials   \n",
       "\n",
       "   r_norm_year  r_length  r_budget r_mpaa  _sim_score  label  \n",
       "0         1999     109.0  35000000      R    0.833333      1  \n",
       "1         2006     139.0  24000000     PG    1.000000      1  \n",
       "2         2012       NaN     20000    NaN    0.666667      0  \n",
       "3         2014     117.0  40000000  PG-13    0.666667      0  \n",
       "4         2015     132.0  61000000  PG-13    1.000000      1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you would like to avoid labeling the pairs for now, you can download the labled.csv file from\n",
    "# BigGorilla using the following command (if you prefer to do it yourself, command the next line)\n",
    "\n",
    "labeled = em.read_csv_metadata('./data/labeled.csv', ltable=kaggle_data, rtable=imdb_data,\n",
    "\t\t\t\t\t\t\t   fk_ltable='l_id', fk_rtable='r_id', key='_id')\n",
    "labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "\n",
    "split = em.split_train_test(labeled, train_proportion=0.5, random_state=0)\n",
    "train_data = split['train']\n",
    "test_data = split['test']\n",
    "\n",
    "dt = em.DTMatcher(name='DecisionTree', random_state=0)\n",
    "svm = em.SVMMatcher(name='SVM', random_state=0)\n",
    "rf = em.RFMatcher(name='RF', random_state=0)\n",
    "lg = em.LogRegMatcher(name='LogReg', random_state=0)\n",
    "ln = em.LinRegMatcher(name='LinReg')\n",
    "nb = em.NBMatcher(name='NaiveBayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting features \n",
    "attr_corres = em.get_attr_corres(kaggle_data, imdb_data)\n",
    "attr_corres['corres'] = [('norm_movie_title', 'norm_title'), \n",
    "\t\t\t\t\t\t ('norm_title_year', 'norm_year'),\n",
    "\t\t\t\t\t\t('content_rating', 'mpaa'),\n",
    "\t\t\t\t\t\t ('budget', 'budget'),\n",
    "]\n",
    "\n",
    "l_attr_types = em.get_attr_types(kaggle_data)\n",
    "r_attr_types = em.get_attr_types(imdb_data)\n",
    "\n",
    "tok = em.get_tokenizers_for_matching()\n",
    "sim = em.get_sim_funs_for_matching()\n",
    "\n",
    "F = em.get_features(kaggle_data, imdb_data, l_attr_types, r_attr_types, attr_corres, tok, sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ali\\miniconda3\\lib\\site-packages\\py_entitymatching\\matcher\\matcherutils.py:224: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  imp.statistics_[pd.np.isnan(imp.statistics_)] = val_all_nans\n"
     ]
    }
   ],
   "source": [
    "# imported numpy\n",
    "import numpy as np\n",
    "train_features = em.extract_feature_vecs(train_data, feature_table=F, attrs_after='label', show_progress=False) \n",
    "train_features = em.impute_table(train_features, missing_val=np.nan ,exclude_attrs=['_id', 'l_id', 'r_id', 'label'], strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>Average recall</th>\n",
       "      <th>Average f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.993548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.993548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.946970</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.964853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.993548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.974326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.993548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Matcher  Average precision  Average recall  Average f1\n",
       "0  DecisionTree           1.000000          0.9875    0.993548\n",
       "1            RF           1.000000          0.9875    0.993548\n",
       "2           SVM           0.946970          0.9875    0.964853\n",
       "3        LinReg           1.000000          0.9875    0.993548\n",
       "4        LogReg           0.963333          0.9875    0.974326\n",
       "5    NaiveBayes           1.000000          0.9875    0.993548"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints the result table \n",
    "result = em.select_matcher([dt, rf, svm, ln, lg, nb], table=train_features, \n",
    "\t\t\t\t\t\t   exclude_attrs=['_id', 'l_id', 'r_id', 'label'], k=5,\n",
    "\t\t\t\t\t\t   target_attr='label', random_state=0)\n",
    "result['cv_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 94.44% (51/54)\n",
      "Recall : 100.0% (51/51)\n",
      "F1 : 97.14%\n",
      "False positives : 3 (out of 54 positive predictions)\n",
      "False negatives : 0 (out of 196 negative predictions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ali\\miniconda3\\lib\\site-packages\\py_entitymatching\\matcher\\matcherutils.py:224: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  imp.statistics_[pd.np.isnan(imp.statistics_)] = val_all_nans\n"
     ]
    }
   ],
   "source": [
    "# Evaluating quality of the dataset \n",
    "\n",
    "best_model = result['selected_matcher']\n",
    "best_model.fit(table=train_features, exclude_attrs=['_id', 'l_id', 'r_id', 'label'], target_attr='label')\n",
    "\n",
    "test_features = em.extract_feature_vecs(test_data, feature_table=F, attrs_after='label', show_progress=False)\n",
    "test_features = em.impute_table(test_features, missing_val=np.nan, exclude_attrs=['_id', 'l_id', 'r_id', 'label'], strategy='mean')\n",
    "\n",
    "# Predict on the test data\n",
    "predictions = best_model.predict(table=test_features, exclude_attrs=['_id', 'l_id', 'r_id', 'label'], \n",
    "\t\t\t\t\t\t\t\t append=True, target_attr='predicted', inplace=False)\n",
    "\n",
    "# Evaluate the predictions\n",
    "eval_result = em.eval_matches(predictions, 'label', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:10\n",
      "c:\\Users\\Ali\\miniconda3\\lib\\site-packages\\py_entitymatching\\matcher\\matcherutils.py:224: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  imp.statistics_[pd.np.isnan(imp.statistics_)] = val_all_nans\n"
     ]
    }
   ],
   "source": [
    "# Using the trained model to match the datasets \n",
    "\n",
    "\n",
    "candset_features = em.extract_feature_vecs(C, feature_table=F, show_progress=True)\n",
    "candset_features = em.impute_table(candset_features, missing_val=np.nan,  exclude_attrs=['_id', 'l_id', 'r_id'], strategy='mean')\n",
    "predictions = best_model.predict(table=candset_features, exclude_attrs=['_id', 'l_id', 'r_id'],\n",
    "\t\t\t\t\t\t\t\t append=True, target_attr='predicted', inplace=False)\n",
    "matches = predictions[predictions.predicted == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>l_id</th>\n",
       "      <th>r_id</th>\n",
       "      <th>l_norm_movie_title</th>\n",
       "      <th>l_norm_title_year</th>\n",
       "      <th>l_budget</th>\n",
       "      <th>l_content_rating</th>\n",
       "      <th>r_norm_title</th>\n",
       "      <th>r_norm_year</th>\n",
       "      <th>r_budget</th>\n",
       "      <th>r_mpaa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4352</td>\n",
       "      <td>106</td>\n",
       "      <td>#horror</td>\n",
       "      <td>2015</td>\n",
       "      <td>1500000</td>\n",
       "      <td>Not Rated</td>\n",
       "      <td>#horror</td>\n",
       "      <td>2015</td>\n",
       "      <td>1500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2726</td>\n",
       "      <td>450</td>\n",
       "      <td>crocodile dundee ii</td>\n",
       "      <td>1988</td>\n",
       "      <td>15800000</td>\n",
       "      <td>PG</td>\n",
       "      <td>crocodile dundee ii</td>\n",
       "      <td>1988</td>\n",
       "      <td>14000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>3406</td>\n",
       "      <td>838</td>\n",
       "      <td>500 days of summer</td>\n",
       "      <td>2009</td>\n",
       "      <td>7500000</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>(500) days of summer</td>\n",
       "      <td>2009</td>\n",
       "      <td>7500000</td>\n",
       "      <td>PG-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>3631</td>\n",
       "      <td>1872</td>\n",
       "      <td>10 cloverfield lane</td>\n",
       "      <td>2016</td>\n",
       "      <td>15000000</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>10 cloverfield lane</td>\n",
       "      <td>2016</td>\n",
       "      <td>15000000</td>\n",
       "      <td>PG-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>2965</td>\n",
       "      <td>1881</td>\n",
       "      <td>10 days in a madhouse</td>\n",
       "      <td>2015</td>\n",
       "      <td>12000000</td>\n",
       "      <td>R</td>\n",
       "      <td>10 days in delaware</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id  l_id  r_id     l_norm_movie_title l_norm_title_year  l_budget  \\\n",
       "0    4  4352   106                #horror              2015   1500000   \n",
       "1    8  2726   450    crocodile dundee ii              1988  15800000   \n",
       "2   11  3406   838     500 days of summer              2009   7500000   \n",
       "3   25  3631  1872    10 cloverfield lane              2016  15000000   \n",
       "4   26  2965  1881  10 days in a madhouse              2015  12000000   \n",
       "\n",
       "  l_content_rating          r_norm_title r_norm_year  r_budget r_mpaa  \n",
       "0        Not Rated               #horror        2015   1500000    NaN  \n",
       "1               PG   crocodile dundee ii        1988  14000000    NaN  \n",
       "2            PG-13  (500) days of summer        2009   7500000  PG-13  \n",
       "3            PG-13   10 cloverfield lane        2016  15000000  PG-13  \n",
       "4                R   10 days in delaware        2015         0    NaN  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the matches catalog results \n",
    "from py_entitymatching.catalog import catalog_manager as cm\n",
    "matches = matches[['_id', 'l_id', 'r_id', 'predicted']]\n",
    "matches.reset_index(drop=True, inplace=True)\n",
    "cm.set_candset_properties(matches, '_id', 'l_id', 'r_id', kaggle_data, imdb_data)\n",
    "matches = em.add_output_attributes(matches, l_output_attrs=['norm_movie_title', 'norm_title_year', 'budget', 'content_rating'],\n",
    "\t\t\t\t\t\t\t\t   r_output_attrs=['norm_title', 'norm_year', 'budget', 'mpaa'],\n",
    "\t\t\t\t\t\t\t\t   l_output_prefix='l_', r_output_prefix='r_',\n",
    "\t\t\t\t\t\t\t\t   delete_from_catalog=False)\n",
    "matches.drop('predicted', axis=1, inplace=True)\n",
    "matches.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "abc030ceda3fa41b1033bd06889a319332e54a2aa5c62425fac5abb05d76f141"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
